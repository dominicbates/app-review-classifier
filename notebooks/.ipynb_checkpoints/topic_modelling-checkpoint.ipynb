{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import LdaMulticore\n",
    "import os, re\n",
    "sub_dir = '/Users/dominicbates/Documents/GitHub/app-review-classifier/'\n",
    "os.chdir(sub_dir)\n",
    "\n",
    "from app_review_classifier.text_processing import TextCleaner, Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_parquet('/Users/dominicbates/Documents/GitHub/app-review-classifier/data/reviews_sample.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up text and removing stopwords...\n",
      "- Text cleaned in: 0.24 seconds\n",
      "\n",
      "Training ngrams...\n",
      "- Training done in: 1.29 seconds\n",
      "\n",
      "Loading spacy model...\n",
      "- Model loaded in: 0.6 seconds\n",
      "\n",
      "Lemmasizing...\n",
      "- Lemmatizing done in: 35.36 seconds\n",
      "\n",
      "Original N. reviews: 14986\n",
      "After removing short reviews: 5846\n"
     ]
    }
   ],
   "source": [
    "# Get cleaner object\n",
    "cleaner = TextCleaner(config={'stop_words':True,'ngrams':True,'lemmatization':True})\n",
    "\n",
    "# Clean text\n",
    "cleaned_reviews = cleaner.process_raw_text(reviews_df['review'], train_ngrams = True)\n",
    "\n",
    "# Remove really short reviews\n",
    "print('\\nOriginal N. reviews:',len(cleaned_reviews))\n",
    "cleaned_reviews = [review for review in cleaned_reviews if len(review)>=10]\n",
    "print('After removing short reviews:',len(cleaned_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Embedder(method='word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting word2vec model\n",
      "- Setting up model...\n",
      "- Setup done!\n",
      "- Building Vocab...\n",
      "- Vocab built!\n",
      "- Training Model...\n",
      "- Model training finished!\n"
     ]
    }
   ],
   "source": [
    "test.fit(cleaned_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_configs = {'lda':{'num_topics':10,\n",
    "                          'passes':2, # Default 1 just tried 50\n",
    "                          'iterations':500, # Default 50\n",
    "                          'random_state':1234}}\n",
    "\n",
    "class TopicModel:\n",
    "    \n",
    "    def __init__(self, \n",
    "                 config=None):\n",
    "        \n",
    "        # Set config params\n",
    "        if config is None:\n",
    "            self.config = default_configs['lda']\n",
    "        else:\n",
    "            self.config = config\n",
    "            \n",
    "        self.model = None\n",
    "        self.num_topics = self.config['num_topics']\n",
    "        self.training_passes = self.config['passes']\n",
    "        self.training_iterations = self.config['iterations']\n",
    "        self.training_random_state = self.config['random_state']\n",
    "\n",
    "    \n",
    "    def get_corpus(self, documents, train_dict=False):\n",
    "        print('Getting corpus...')\n",
    "        t1=time.time()\n",
    "        if train_dict==True:\n",
    "            print('Training dictionary...')\n",
    "            self.id2word = corpora.Dictionary(documents)\n",
    "            \n",
    "            if self.id2word is None:\n",
    "                raise ValueError('No dictionary trained yet. Try ruynning get_corpus() with train=True')\n",
    "            \n",
    "        print('Done in: {} seconds'.format(round((time.time() - t1), 2)))\n",
    "        return [self.id2word.doc2bow(text) for text in cleaned_reviews]\n",
    "                    \n",
    "\n",
    "    def fit(self, documents):\n",
    "\n",
    "        corpus = self.get_corpus(documents, train_dict=True)\n",
    "        \n",
    "        print('\\nTraining model...')\n",
    "        t1=time.time()\n",
    "        self.model = LdaMulticore(corpus=corpus,\n",
    "                                  id2word=self.id2word,\n",
    "                                  num_topics=self.num_topics,\n",
    "                                  passes = self.training_passes, # Default 1 just tried 50\n",
    "                                  iterations = self.training_iterations, # Default 50\n",
    "                                  random_state=self.training_random_state,\n",
    "                                  eval_every=10)        \n",
    "        print('Model trained in: {} seconds'.format(round((time.time() - t1), 2)))\n",
    "\n",
    "\n",
    "    def apply(self, documents):\n",
    "        corpus = self.get_corpus(documents, train_dict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting corpus...\n",
      "Training dictionary...\n",
      "Done in: 0.23 seconds\n",
      "\n",
      "Training model...\n",
      "Model trained in: 5.22 seconds\n"
     ]
    }
   ],
   "source": [
    "test_model = TopicModel()\n",
    "test_model.fit(cleaned_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# default_configs = {'lda':{num_topics=10,\n",
    "#                           passes = 2000, # Default 1 just tried 50\n",
    "#                           iterations = 500, # Default 50\n",
    "#                           random_state=1234}}\n",
    "\n",
    "\n",
    "# print('Training model...')\n",
    "# t1=time.time()\n",
    "# lda_model = LdaMulticore(corpus=corpus,\n",
    "#                          id2word=id2word,\n",
    "#                          num_topics=10,\n",
    "#                          passes = 2000, # Default 1 just tried 50\n",
    "#                          iterations = 500, # Default 50\n",
    "#                          random_state=1234,\n",
    "#                          eval_every=10)\n",
    "# print('Model trained in: {} seconds'.format(round((time.time() - t1), 2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'print_topics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-b497eccac8a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# corpus=self.training_bow,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# num_topics=params[\"num_topics\"],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# iterations=params[\"iterations\"],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'print_topics'"
     ]
    }
   ],
   "source": [
    "test_model.model.print_topics()\n",
    "\n",
    "# corpus=self.training_bow,\n",
    "# num_topics=params[\"num_topics\"],\n",
    "# iterations=params[\"iterations\"],\n",
    "# id2word=self.training_dictionary,\n",
    "# passes=params[\"passes\"],\n",
    "# alpha=params[\"alpha\"],\n",
    "# eta=params[\"eta\"],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
